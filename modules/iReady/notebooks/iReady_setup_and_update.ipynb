{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## iReady Data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "storage_account = 'steduanalytics__update_this'\n",
        "use_test_env = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "if use_test_env:\n",
        "    stage1 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage1'\n",
        "    stage2 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage2'\n",
        "    stage3 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage3'\n",
        "else:\n",
        "    stage1 = 'abfss://stage1@' + storage_account + '.dfs.core.windows.net'\n",
        "    stage2 = 'abfss://stage2@' + storage_account + '.dfs.core.windows.net'\n",
        "    stage3 = 'abfss://stage3@' + storage_account + '.dfs.core.windows.net'"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Process personalized_instruction_by_lesson_math.csv\n",
        "def remove_spaces(str): return str.replace(' ', '').replace('(','_').replace(')','_').replace('=', '__')\n",
        "\n",
        "def process(filename):\n",
        "  df = spark.read.csv(stage1 + '/iready/' + filename + '.csv', header='true', inferSchema='true')\n",
        "  newColumns = map(remove_spaces, df.columns)\n",
        "  df = df.toDF(*newColumns)\n",
        "  df = df.withColumn('StudentID',df.StudentID.cast('string')) # StudentID needs to be a string to allow for hashing when moving into stage3\n",
        "  df.write.format('parquet').mode('overwrite').save(stage2 + '/iready/' + filename)\n",
        "\n",
        "process('comprehensive_student_lesson_activity_with_standards_ela')\n",
        "process('comprehensive_student_lesson_activity_with_standards_math')\n",
        "process('diagnostic_and_instruction_ela_ytd_window')\n",
        "process('diagnostic_and_instruction_math_ytd_window')\n",
        "process('diagnostic_results_ela')\n",
        "process('diagnostic_results_math')\n",
        "process('personalized_instruction_by_lesson_ela')\n",
        "process('personalized_instruction_by_lesson_math')\n",
        "\n",
        "# Anonymize data and load into stage3\n",
        "from pyspark.sql.functions import sha2, lit\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/comprehensive_student_lesson_activity_with_standards_ela')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/comprehensive_student_lesson_activity_with_standards_ela')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/comprehensive_student_lesson_activity_with_standards_math')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/comprehensive_student_lesson_activity_with_standards_math')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/diagnostic_and_instruction_ela_ytd_window')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*')).withColumn('UserName', lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/diagnostic_and_instruction_ela_ytd_window')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/diagnostic_and_instruction_math_ytd_window')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*')).withColumn('UserName', lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/diagnostic_and_instruction_math_ytd_window')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/diagnostic_results_ela')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/diagnostic_results_ela')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/diagnostic_results_math')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/diagnostic_results_math')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/personalized_instruction_by_lesson_ela')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/personalized_instruction_by_lesson_ela')\n",
        "\n",
        "df = spark.read.format('parquet').load(stage2 + '/iready/personalized_instruction_by_lesson_math')\n",
        "df = df.withColumn('StudentID', sha2(df.StudentID, 256)).withColumn('LastName',lit('*')).withColumn('FirstName',lit('*'))\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/iready/personalized_instruction_by_lesson_math')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Create sql on-demand db's for iReady data\n",
        "def create_spark_db(db_name, source_path):\n",
        "    spark.sql('CREATE DATABASE IF NOT EXISTS ' + db_name)\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".comprehensive_student_lesson_activity_with_standards_ela using PARQUET location '\" + source_path + \"/comprehensive_student_lesson_activity_with_standards_ela'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".comprehensive_student_lesson_activity_with_standards_math using PARQUET location '\" + source_path + \"/comprehensive_student_lesson_activity_with_standards_math'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".diagnostic_and_instruction_ela_ytd_window using PARQUET location '\" + source_path + \"/diagnostic_and_instruction_ela_ytd_window'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".diagnostic_and_instruction_math_ytd_window using PARQUET location '\" + source_path + \"/diagnostic_and_instruction_math_ytd_window'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".diagnostic_results_ela using PARQUET location '\" + source_path + \"/diagnostic_results_ela'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".diagnostic_results_math using PARQUET location '\" + source_path + \"/diagnostic_results_math'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".personalized_instruction_by_lesson_ela using PARQUET location '\" + source_path + \"/personalized_instruction_by_lesson_ela'\")\n",
        "    spark.sql(\"create table if not exists \" + db_name + \".personalized_instruction_by_lesson_math using PARQUET location '\" + source_path + \"/personalized_instruction_by_lesson_math'\")\n",
        "\n",
        "db_prefix = 'test_' if use_test_env else ''\n",
        "create_spark_db(db_prefix + 's2_iready', stage2 + '/iready')\n",
        "create_spark_db(db_prefix + 's3_iready', stage3 + '/iready')"
      ]
    }
  ]
}